{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('housing.csv')\n",
    "print(df.head())\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df.medv.values\n",
    "data = df.drop(['medv'], axis=1)\n",
    "data.iloc[:, :] /= data.iloc[:, :].max()\n",
    "data = data.values\n",
    "#print(target)\n",
    "#print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(data, target, test_size=0.2)\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_data = len(data[0])\n",
    "print(nr_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "\n",
    "# input\n",
    "x = tf.placeholder(tf.float32, [None, nr_data])\n",
    "# hidden\n",
    "W1 = tf.Variable(tf.random_uniform([nr_data, 50], -1.0, 1.0))\n",
    "b1 = tf.Variable(tf.zeros([50]))\n",
    "h1 = tf.matmul(x, W1) + b1\n",
    "# output\n",
    "W2 = tf.Variable(tf.random_uniform([50, 20], -1.0, 1.0))\n",
    "b2 = tf.Variable(tf.zeros([20]))\n",
    "h2 = tf.matmul(h1, W2) + b2\n",
    "# output\n",
    "W3 = tf.Variable(tf.random_uniform([20, 1], -1.0, 1.0))\n",
    "b3 = tf.Variable(tf.zeros([1]))\n",
    "o = tf.matmul(h2, W3) + b3\n",
    "\n",
    "y_ = tf.placeholder(tf.float32, [None])\n",
    "#\n",
    "loss = tf.reduce_mean(tf.square(o - y_))\n",
    "#optimizer = tf.train.GradientDescentOptimizer(0.015)\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for step in range(10000):\n",
    "    X_batch = []\n",
    "    Y_batch = []\n",
    "    for n in range(100):\n",
    "        i = random.randrange(len(X_train))\n",
    "        X_batch.append(X_train[i])\n",
    "        Y_batch.append(Y_train[i])\n",
    "    result = sess.run(loss, feed_dict={x:X_train, y_:Y_train})\n",
    "    sess.run(train, feed_dict={x:X_batch, y_:Y_batch})\n",
    "    if step % 1000 == 0:\n",
    "        print(step, result, sess.run(loss, feed_dict={x:X_test, y_:Y_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(sess.run(W1), sess.run(b1))\n",
    "print(sess.run(W2), sess.run(b2))\n",
    "print(sess.run(W3), sess.run(b3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
